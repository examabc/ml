Slip 27 :

Q.1.	Create a multiple linear regression model for house price dataset divide dataset into train and test data while giving it to model and predict prices of house


# Import necessary libraries import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
 


# Step 1: Load the dataset (You can replace this with your actual dataset) # For illustration, we will use a sample dataset.
# Example: 'House Price Dataset' with features like Area, Rooms, and other factors # Replace this with your actual dataset file, such as 'house_prices.csv'

# For illustration, creating a sample dataset data = {
'Area': [1500, 1800, 2400, 3000, 3500, 4000],

'Rooms': [3, 4, 4, 5, 5, 6],

'Age': [10, 15, 20, 25, 30, 35],

'Price': [400000, 450000, 600000, 650000, 700000, 750000] # Target variable
(Price)

}


# Convert to pandas DataFrame df = pd.DataFrame(data)

# Step 2: Preprocess the data

# We will separate features (independent variables) and target (dependent variable)

X = df[['Area', 'Rooms', 'Age']] # Independent variables y = df['Price'] # Dependent variable (house price)
 


# Step 3: Split the data into training and test sets

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Step 4: Create a Linear Regression model model = LinearRegression()

# Step 5: Train the model on the training data model.fit(X_train, y_train)

# Step 6: Make predictions on the test data y_pred = model.predict(X_test)

# Step 7: Evaluate the model's performance

# Calculate Mean Squared Error and R-squared (R2) mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)


# Print results

print(f"Mean Squared Error (MSE): {mse}") print(f"R-squared (R2): {r2}")
 


# Step 8: Predict prices of houses (Example: predicting for new data) # For a new house with 2500 sqft, 4 rooms, and 15 years old:
new_house_data = np.array([[2500, 4, 15]]) # New data (Area, Rooms, Age) predicted_price = model.predict(new_house_data)
print(f"Predicted Price for the new house: ${predicted_price[0]:,.2f}")



Q.2.	Fit the simple linear regression and polynomial linear regression models to Salary_positions.csv data. Find which one is more accurately fitting to the given data. Also predict the salaries of level 11 and level 12 employees.


import pandas as pd import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score

# Step 1: Load the dataset
# Replace 'Salary_positions.csv' with the actual path of your CSV file df = pd.read_csv('Salary_positions.csv')

# Step 2: Preprocess the data
# Assuming the dataset has 'Level' and 'Salary' columns
X = df['Level'].values.reshape(-1, 1) # Independent variable (Level) y = df['Salary'].values # Dependent variable (Salary)

# Step 3: Split the dataset into training and testing sets (80% train, 20% test) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
 
# Step 4: Simple Linear Regression Model linear_regressor = LinearRegression() linear_regressor.fit(X_train, y_train)

# Step 5: Predict salary using Simple Linear Regression y_pred_linear = linear_regressor.predict(X_test)

# Step 6: Polynomial Linear Regression Model (degree 4) poly = PolynomialFeatures(degree=4)
X_poly = poly.fit_transform(X_train) # Transform training data poly_regressor = LinearRegression()
poly_regressor.fit(X_poly, y_train)

# Step 7: Predict salary using Polynomial Regression X_test_poly = poly.transform(X_test) # Transform test data y_pred_poly = poly_regressor.predict(X_test_poly)

# Step 8: Evaluate the models (R-squared and Mean Squared Error) # Simple Linear Regression
linear_r2 = r2_score(y_test, y_pred_linear)
linear_mse = mean_squared_error(y_test, y_pred_linear)

# Polynomial Linear Regression poly_r2 = r2_score(y_test, y_pred_poly)
poly_mse = mean_squared_error(y_test, y_pred_poly)

# Print the results
print(f"Simple Linear Regression R2: {linear_r2:.4f}") print(f"Simple Linear Regression MSE: {linear_mse:.4f}") print(f"Polynomial Linear Regression R2: {poly_r2:.4f}") print(f"Polynomial Linear Regression MSE: {poly_mse:.4f}")

# Step 9: Predict salaries of level 11 and level 12 employees level_11 = np.array([[11]]) # Level 11
level_12 = np.array([[12]]) # Level 12

# Predict using Simple Linear Regression salary_11_linear = linear_regressor.predict(level_11) salary_12_linear = linear_regressor.predict(level_12)

# Predict using Polynomial Linear Regression
 
salary_11_poly = poly_regressor.predict(poly.transform(level_11)) salary_12_poly = poly_regressor.predict(poly.transform(level_12))

# Display results
print(f"Predicted Salary for Level 11 (Simple Linear Regression):
{salary_11_linear[0]:,.2f}")
print(f"Predicted Salary for Level 12 (Simple Linear Regression):
{salary_12_linear[0]:,.2f}")
print(f"Predicted Salary for Level 11 (Polynomial Regression):
{salary_11_poly[0]:,.2f}")
print(f"Predicted Salary for Level 12 (Polynomial Regression):
{salary_12_poly[0]:,.2f}")

# Step 10: Visualize the results (Optional) plt.figure(figsize=(10, 6))

# Plot Simple Linear Regression results plt.subplot(1, 2, 1)
plt.scatter(X, y, color='red')
plt.plot(X, linear_regressor.predict(X), color='blue') plt.title('Simple Linear Regression') plt.xlabel('Level')
plt.ylabel('Salary')

# Plot Polynomial Linear Regression results plt.subplot(1, 2, 2)
plt.scatter(X, y, color='red') plt.plot(np.arange(1, 13).reshape(-1, 1),
poly_regressor.predict(poly.transform(np.arange(1, 13).reshape(-1, 1))), color='blue') plt.title('Polynomial Linear Regression')
plt.xlabel('Level') plt.ylabel('Salary')

plt.tight_layout() plt.show()
